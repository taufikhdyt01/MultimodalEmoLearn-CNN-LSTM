{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Complete Preprocessing Pipeline for Emotion Recognition\n",
        "\n",
        "This notebook provides a complete preprocessing pipeline that:\n",
        "1. Cleans and organizes data by sample\n",
        "2. Generates emotion labels from Face API data\n",
        "3. Splits dataset into train/validation/test sets\n",
        "4. Prepares data for CNN (images) and LSTM (landmarks)\n",
        "\n",
        "## Configuration\n",
        "Modify the paths below according to your directory structure:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration - Modify these paths according to your setup\n",
        "EXCEL_PATH = \"D:/Preprocessing/all_samples_data.xlsx\"  # Path to your Excel file with all samples\n",
        "BASE_DIR = \"D:/Preprocessing\"                         # Base directory containing all sample folders\n",
        "OUTPUT_BASE_DIR = \"D:/Preprocessing/Cleaned\"          # Where to save cleaned data\n",
        "FINAL_OUTPUT_DIR = \"D:/Preprocessing/Final_Dataset\"   # Final output directory\n",
        "\n",
        "# Sample to user_id mapping\n",
        "SAMPLE_TO_USER_ID = {\n",
        "    1: 97, 2: 117, 3: 99, 4: 100, 5: 101, 6: 103, 7: 102, 8: 118, 9: 104, 10: 106,\n",
        "    11: 107, 12: 108, 13: 109, 14: 110, 15: 111, 16: 112, 17: 114, 18: 113, 19: 115, 20: 116\n",
        "}\n",
        "\n",
        "# Preprocessing parameters\n",
        "CONFIDENCE_THRESHOLD = 0.5\n",
        "TRAIN_SIZE = 0.8\n",
        "VAL_SIZE = 0.1\n",
        "TEST_SIZE = 0.1\n",
        "IMG_SIZE = (224, 224)  # For CNN input\n",
        "RANDOM_STATE = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import shutil\n",
        "import json\n",
        "import re\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Create necessary directories\n",
        "os.makedirs(OUTPUT_BASE_DIR, exist_ok=True)\n",
        "os.makedirs(FINAL_OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "print(\"Libraries imported and directories created successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Data Cleaning and Organization\n",
        "\n",
        "This step cleans the data and organizes it by sample (not by challenge). It matches timestamps with frame images and filters out low-confidence records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_time_from_timestamp(timestamp):\n",
        "    \"\"\"Extract time from timestamp and format for matching with frame filenames.\"\"\"\n",
        "    try:\n",
        "        if isinstance(timestamp, pd.Timestamp):\n",
        "            dt = timestamp\n",
        "        else:\n",
        "            try:\n",
        "                dt = datetime.strptime(timestamp, \"%d/%m/%Y %H:%M:%S\")\n",
        "            except ValueError:\n",
        "                try:\n",
        "                    dt = datetime.strptime(timestamp, \"%Y-%m-%d %H:%M:%S\")\n",
        "                except ValueError:\n",
        "                    dt = pd.to_datetime(timestamp)\n",
        "        \n",
        "        return f\"{dt.hour:02d}_{dt.minute:02d}_{dt.second:02d}\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing timestamp {timestamp}: {e}\")\n",
        "        return None\n",
        "\n",
        "def extract_challenge_from_page(page):\n",
        "    \"\"\"Extract challenge name from page URL.\"\"\"\n",
        "    if pd.isna(page) or not isinstance(page, str):\n",
        "        return \"Unknown\"\n",
        "        \n",
        "    if '/tantangan/' in page:\n",
        "        parts = page.split('/')\n",
        "        try:\n",
        "            tantangan_index = parts.index('tantangan')\n",
        "            if tantangan_index + 1 < len(parts) and parts[tantangan_index + 1]:\n",
        "                return parts[tantangan_index + 1]\n",
        "        except ValueError:\n",
        "            pass\n",
        "    return \"Other\"\n",
        "\n",
        "def process_sample_simplified(sample_num, user_id, df_all, base_dir, output_base_dir):\n",
        "    \"\"\"Process a single sample - simplified version without challenge separation.\"\"\"\n",
        "    # Filter dataframe for this user_id\n",
        "    df_sample = df_all[df_all['user_id'] == user_id].copy()\n",
        "    \n",
        "    if df_sample.empty:\n",
        "        print(f\"No data found for Sample {sample_num} (user_id: {user_id})\")\n",
        "        return pd.DataFrame(), []\n",
        "    \n",
        "    # Define source directory for frames\n",
        "    frames_dir = os.path.join(base_dir, f\"Sample {sample_num}\", \"frames\")\n",
        "    \n",
        "    if not os.path.exists(frames_dir):\n",
        "        print(f\"Frames directory not found for Sample {sample_num}: {frames_dir}\")\n",
        "        return pd.DataFrame(), []\n",
        "    \n",
        "    # Create output directory for this sample\n",
        "    sample_output_dir = os.path.join(output_base_dir, f\"Sample {sample_num}\", \"cleaned_frames\")\n",
        "    os.makedirs(sample_output_dir, exist_ok=True)\n",
        "    \n",
        "    # Get all frame files in the directory\n",
        "    frame_files = {}\n",
        "    for filename in os.listdir(frames_dir):\n",
        "        if filename.startswith('frame_') and filename.endswith('.jpg'):\n",
        "            time_parts = filename.replace('frame_', '').replace('.jpg', '')\n",
        "            frame_files[time_parts] = filename\n",
        "    \n",
        "    # Add challenge information to the dataframe\n",
        "    if 'page' in df_sample.columns:\n",
        "        df_sample['Challenge'] = df_sample['page'].apply(extract_challenge_from_page)\n",
        "    \n",
        "    matched_indices = []\n",
        "    matched_times = set()\n",
        "    \n",
        "    # Process all records for this sample\n",
        "    for index, row in df_sample.iterrows():\n",
        "        time_key = extract_time_from_timestamp(row['timestamp'])\n",
        "        if not time_key:\n",
        "            continue\n",
        "        \n",
        "        # Check if we have a matching frame\n",
        "        if time_key in frame_files:\n",
        "            # Check confidence\n",
        "            emotion_cols = ['neutral', 'happy', 'sad', 'angry', 'fearful', 'disgusted', 'surprised']\n",
        "            emotion_values = []\n",
        "            \n",
        "            for col in emotion_cols:\n",
        "                if col in row:\n",
        "                    try:\n",
        "                        emotion_values.append(float(row[col]))\n",
        "                    except (ValueError, TypeError):\n",
        "                        emotion_values.append(0.0)\n",
        "            \n",
        "            if emotion_values:\n",
        "                max_confidence = max(emotion_values)\n",
        "                \n",
        "                is_valid = (max_confidence >= CONFIDENCE_THRESHOLD and \n",
        "                           (pd.isna(row.get('Classification', None)) or row.get('Classification', '') != 'Low Confidence'))\n",
        "                \n",
        "                if is_valid:\n",
        "                    # Keep this record and copy the corresponding frame\n",
        "                    matched_indices.append(index)\n",
        "                    matched_times.add(time_key)\n",
        "                    \n",
        "                    src_path = os.path.join(frames_dir, frame_files[time_key])\n",
        "                    dst_path = os.path.join(sample_output_dir, frame_files[time_key])\n",
        "                    shutil.copy2(src_path, dst_path)\n",
        "    \n",
        "    # Find frames that don't match any record\n",
        "    unmatched_frames = []\n",
        "    for time_key, filename in frame_files.items():\n",
        "        if time_key not in matched_times:\n",
        "            unmatched_frames.append(filename)\n",
        "    \n",
        "    # Create DataFrame with matched records\n",
        "    matched_df = df_sample.loc[matched_indices].copy() if matched_indices else pd.DataFrame()\n",
        "    \n",
        "    # Save sample-specific Excel\n",
        "    if not matched_df.empty:\n",
        "        sample_excel_dir = os.path.join(output_base_dir, f\"Sample {sample_num}\")\n",
        "        sample_excel_path = os.path.join(sample_excel_dir, \"cleaned_data.xlsx\")\n",
        "        matched_df.to_excel(sample_excel_path, index=False)\n",
        "    \n",
        "    print(f\"Sample {sample_num} (user_id: {user_id}):\")\n",
        "    print(f\"  - Total records: {len(df_sample)}\")\n",
        "    print(f\"  - Valid matched records: {len(matched_df)}\")\n",
        "    print(f\"  - Unmatched frames: {len(unmatched_frames)}\")\n",
        "    \n",
        "    return matched_df, unmatched_frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Execute data cleaning\n",
        "print(\"Starting data cleaning process...\")\n",
        "print(f\"Loading data from {EXCEL_PATH}...\")\n",
        "\n",
        "try:\n",
        "    df_all = pd.read_excel(EXCEL_PATH)\n",
        "    print(f\"Loaded {len(df_all)} records.\")\n",
        "    \n",
        "    # Convert timestamp column to datetime if needed\n",
        "    if 'timestamp' in df_all.columns and not pd.api.types.is_datetime64_any_dtype(df_all['timestamp']):\n",
        "        df_all['timestamp'] = pd.to_datetime(df_all['timestamp'], errors='coerce')\n",
        "        \n",
        "    print(\"\\nAvailable columns:\", df_all.columns.tolist())\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"Error loading Excel file: {e}\")\n",
        "    raise\n",
        "\n",
        "# Process each sample\n",
        "all_matched_dfs = []\n",
        "all_stats = {}\n",
        "\n",
        "print(\"\\nProcessing samples...\")\n",
        "for sample_num, user_id in SAMPLE_TO_USER_ID.items():\n",
        "    print(f\"\\nProcessing Sample {sample_num} (user_id: {user_id})...\")\n",
        "    matched_df, unmatched_frames = process_sample_simplified(\n",
        "        sample_num, user_id, df_all, BASE_DIR, OUTPUT_BASE_DIR\n",
        "    )\n",
        "    \n",
        "    if not matched_df.empty:\n",
        "        all_matched_dfs.append(matched_df)\n",
        "    \n",
        "    all_stats[sample_num] = {\n",
        "        'user_id': user_id,\n",
        "        'matched_records': len(matched_df),\n",
        "        'unmatched_frames': len(unmatched_frames)\n",
        "    }\n",
        "\n",
        "# Combine all matched records\n",
        "if all_matched_dfs:\n",
        "    combined_df = pd.concat(all_matched_dfs, ignore_index=True)\n",
        "    output_excel = os.path.join(OUTPUT_BASE_DIR, \"all_cleaned_data.xlsx\")\n",
        "    combined_df.to_excel(output_excel, index=False)\n",
        "    print(f\"\\nSaved cleaned data to {output_excel}\")\n",
        "    print(f\"Total cleaned records: {len(combined_df)}\")\n",
        "else:\n",
        "    print(\"\\nNo valid records found across all samples.\")\n",
        "    combined_df = pd.DataFrame()\n",
        "\n",
        "print(\"\\nData cleaning completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Generate Emotion Labels\n",
        "\n",
        "Extract emotion labels from Face API data and create ground truth labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_emotion_labels(df):\n",
        "    \"\"\"Generate emotion labels from Face API data.\"\"\"\n",
        "    if df.empty:\n",
        "        print(\"No data available for emotion label generation.\")\n",
        "        return df\n",
        "    \n",
        "    print(\"Generating emotion labels from Face API data...\")\n",
        "    \n",
        "    # Identify emotion columns\n",
        "    emotion_columns = ['neutral', 'happy', 'sad', 'angry', 'fearful', 'disgusted', 'surprised']\n",
        "    \n",
        "    # Check which emotion columns are available\n",
        "    available_emotions = [col for col in emotion_columns if col in df.columns]\n",
        "    missing_columns = [col for col in emotion_columns if col not in df.columns]\n",
        "    \n",
        "    if missing_columns:\n",
        "        print(f\"Warning: Missing emotion columns: {missing_columns}\")\n",
        "    \n",
        "    if not available_emotions:\n",
        "        print(\"Error: No emotion columns found in the data\")\n",
        "        return df\n",
        "    \n",
        "    # Convert emotion columns to numeric\n",
        "    for col in available_emotions:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
        "    \n",
        "    # Find dominant emotion and confidence score\n",
        "    emotions_only = df[available_emotions]\n",
        "    df['Dominant_Emotion'] = emotions_only.idxmax(axis=1)\n",
        "    df['Confidence_Score'] = emotions_only.max(axis=1)\n",
        "    \n",
        "    # Filter high confidence data\n",
        "    valid_mask = (df['Confidence_Score'] >= CONFIDENCE_THRESHOLD) & \\\n",
        "                 ((df.get('Classification', '') != 'Low Confidence') | df['Classification'].isna())\n",
        "    \n",
        "    high_confidence_df = df[valid_mask].copy()\n",
        "    \n",
        "    # Calculate statistics\n",
        "    total_frames = len(df)\n",
        "    valid_frames = len(high_confidence_df)\n",
        "    valid_percent = (valid_frames / total_frames * 100) if total_frames > 0 else 0\n",
        "    \n",
        "    print(f\"Total frames: {total_frames}\")\n",
        "    print(f\"Frames with high confidence: {valid_frames} ({valid_percent:.2f}%)\")\n",
        "    \n",
        "    # Calculate emotion distribution\n",
        "    if valid_frames > 0:\n",
        "        emotion_distribution = high_confidence_df['Dominant_Emotion'].value_counts()\n",
        "        print(\"\\nEmotion Distribution (High Confidence):\")\n",
        "        for emotion, count in emotion_distribution.items():\n",
        "            percent = (count / valid_frames * 100)\n",
        "            print(f\"  {emotion}: {count} ({percent:.2f}%)\")\n",
        "    \n",
        "    return high_confidence_df\n",
        "\n",
        "# Generate emotion labels\n",
        "if not combined_df.empty:\n",
        "    labeled_df = generate_emotion_labels(combined_df)\n",
        "    \n",
        "    # Save labeled data\n",
        "    labeled_data_path = os.path.join(FINAL_OUTPUT_DIR, \"labeled_data.xlsx\")\n",
        "    labeled_df.to_excel(labeled_data_path, index=False)\n",
        "    print(f\"\\nSaved labeled data to {labeled_data_path}\")\n",
        "else:\n",
        "    print(\"No cleaned data available for emotion labeling.\")\n",
        "    labeled_df = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Split Dataset\n",
        "\n",
        "Split the labeled dataset into training, validation, and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_dataset_advanced(df, output_dir, train_size=0.8, val_size=0.1, test_size=0.1, stratify=True, random_state=42):\n",
        "    \"\"\"Split dataset into train, validation, and test sets.\"\"\"\n",
        "    if df.empty:\n",
        "        print(\"No data available for splitting.\")\n",
        "        return None, None, None\n",
        "    \n",
        "    # Ensure proportions are valid\n",
        "    assert abs((train_size + val_size + test_size) - 1.0) < 1e-10, \"Proportions must sum to 1.0\"\n",
        "    \n",
        "    # Check if required column exists\n",
        "    if 'Dominant_Emotion' not in df.columns:\n",
        "        print(\"Error: 'Dominant_Emotion' column not found. Cannot split dataset.\")\n",
        "        return None, None, None\n",
        "    \n",
        "    total_rows = len(df)\n",
        "    print(f\"Splitting dataset of {total_rows} records...\")\n",
        "    \n",
        "    # Determine stratify parameter\n",
        "    stratify_column = df['Dominant_Emotion'] if stratify else None\n",
        "    \n",
        "    # Split into train and temp (val+test)\n",
        "    train, temp = train_test_split(\n",
        "        df, \n",
        "        train_size=train_size, \n",
        "        random_state=random_state,\n",
        "        stratify=stratify_column\n",
        "    )\n",
        "    \n",
        "    # Update stratify column for next split\n",
        "    if stratify:\n",
        "        stratify_column = temp['Dominant_Emotion']\n",
        "    \n",
        "    # Calculate relative proportion for val vs test\n",
        "    relative_val_size = val_size / (val_size + test_size)\n",
        "    \n",
        "    # Split temp into val and test\n",
        "    val, test = train_test_split(\n",
        "        temp, \n",
        "        train_size=relative_val_size, \n",
        "        random_state=random_state,\n",
        "        stratify=stratify_column\n",
        "    )\n",
        "    \n",
        "    # Create split directory\n",
        "    split_dir = os.path.join(output_dir, \"Dataset_Split\")\n",
        "    os.makedirs(split_dir, exist_ok=True)\n",
        "    \n",
        "    # Save each subset\n",
        "    train.to_excel(os.path.join(split_dir, \"train_data.xlsx\"), index=False)\n",
        "    val.to_excel(os.path.join(split_dir, \"val_data.xlsx\"), index=False)\n",
        "    test.to_excel(os.path.join(split_dir, \"test_data.xlsx\"), index=False)\n",
        "    \n",
        "    # Calculate and print statistics\n",
        "    train_count, val_count, test_count = len(train), len(val), len(test)\n",
        "    \n",
        "    print(f\"Dataset split complete:\")\n",
        "    print(f\"  - Training set: {train_count} ({train_count/total_rows*100:.2f}%)\")\n",
        "    print(f\"  - Validation set: {val_count} ({val_count/total_rows*100:.2f}%)\")\n",
        "    print(f\"  - Test set: {test_count} ({test_count/total_rows*100:.2f}%)\")\n",
        "    \n",
        "    # Print emotion distribution for each set\n",
        "    print(\"\\nEmotion Distribution:\")\n",
        "    for name, dataset in [(\"Training\", train), (\"Validation\", val), (\"Test\", test)]:\n",
        "        emotion_counts = dataset['Dominant_Emotion'].value_counts()\n",
        "        print(f\"\\n{name} Set:\")\n",
        "        for emotion, count in emotion_counts.items():\n",
        "            percent = count / len(dataset) * 100\n",
        "            print(f\"  {emotion}: {count} ({percent:.2f}%)\")\n",
        "    \n",
        "    return train, val, test\n",
        "\n",
        "# Split the dataset\n",
        "if not labeled_df.empty:\n",
        "    train_set, val_set, test_set = split_dataset_advanced(\n",
        "        labeled_df, \n",
        "        FINAL_OUTPUT_DIR, \n",
        "        train_size=TRAIN_SIZE,\n",
        "        val_size=VAL_SIZE,\n",
        "        test_size=TEST_SIZE,\n",
        "        random_state=RANDOM_STATE\n",
        "    )\n",
        "    print(\"\\nDataset splitting completed!\")\n",
        "else:\n",
        "    print(\"No labeled data available for splitting.\")\n",
        "    train_set = val_set = test_set = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Prepare Data for CNN (Images)\n",
        "\n",
        "Prepare image data for CNN training with proper directory structure and numpy arrays."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_sample_number_from_user_id(user_id, user_id_mapping):\n",
        "    \"\"\"Get sample number from user_id using mapping.\"\"\"\n",
        "    for sample_num, uid in user_id_mapping.items():\n",
        "        if uid == user_id:\n",
        "            return sample_num\n",
        "    return None\n",
        "\n",
        "def format_timestamp_to_filename(timestamp):\n",
        "    \"\"\"Convert timestamp to frame filename format.\"\"\"\n",
        "    try:\n",
        "        if pd.isna(timestamp):\n",
        "            return None\n",
        "        \n",
        "        if isinstance(timestamp, pd.Timestamp):\n",
        "            return f\"frame_{timestamp.hour:02d}_{timestamp.minute:02d}_{timestamp.second:02d}.jpg\"\n",
        "        \n",
        "        dt = pd.to_datetime(timestamp)\n",
        "        return f\"frame_{dt.hour:02d}_{dt.minute:02d}_{dt.second:02d}.jpg\"\n",
        "    except Exception as e:\n",
        "        print(f\"Error formatting timestamp {timestamp}: {e}\")\n",
        "        return None\n",
        "\n",
        "def find_image_in_sample_folder(images_dir, sample_num, frame_name):\n",
        "    \"\"\"Find image file in sample folder.\"\"\"\n",
        "    sample_dir = os.path.join(images_dir, f\"Sample {sample_num}\")\n",
        "    if not os.path.exists(sample_dir):\n",
        "        return None\n",
        "    \n",
        "    # Look in cleaned_frames directory\n",
        "    frames_path = os.path.join(sample_dir, \"cleaned_frames\")\n",
        "    if os.path.exists(frames_path):\n",
        "        img_path = os.path.join(frames_path, frame_name)\n",
        "        if os.path.exists(img_path):\n",
        "            return img_path\n",
        "    \n",
        "    return None\n",
        "\n",
        "def prepare_cnn_data(split_dir, images_dir, output_dir, user_id_mapping, img_size=(224, 224)):\n",
        "    \"\"\"Prepare image data for CNN.\"\"\"\n",
        "    print(\"Preparing data for CNN...\")\n",
        "    \n",
        "    cnn_output_dir = os.path.join(output_dir, \"CNN_Data\")\n",
        "    os.makedirs(cnn_output_dir, exist_ok=True)\n",
        "    \n",
        "    split_files = {\n",
        "        'train': os.path.join(split_dir, 'train_data.xlsx'),\n",
        "        'val': os.path.join(split_dir, 'val_data.xlsx'),\n",
        "        'test': os.path.join(split_dir, 'test_data.xlsx')\n",
        "    }\n",
        "    \n",
        "    for split_name, split_file in split_files.items():\n",
        "        if not os.path.exists(split_file):\n",
        "            print(f\"Warning: {split_file} not found. Skipping.\")\n",
        "            continue\n",
        "        \n",
        "        print(f\"\\nProcessing {split_name} data for CNN...\")\n",
        "        df = pd.read_excel(split_file)\n",
        "        \n",
        "        # Create output directories\n",
        "        split_img_dir = os.path.join(cnn_output_dir, f\"{split_name}_images\")\n",
        "        os.makedirs(split_img_dir, exist_ok=True)\n",
        "        \n",
        "        # Create directories for each emotion class\n",
        "        if 'Dominant_Emotion' in df.columns:\n",
        "            emotions = df['Dominant_Emotion'].unique()\n",
        "            for emotion in emotions:\n",
        "                if not pd.isna(emotion):\n",
        "                    os.makedirs(os.path.join(split_img_dir, str(emotion)), exist_ok=True)\n",
        "        else:\n",
        "            print(f\"Error: 'Dominant_Emotion' column not found in {split_file}. Skipping.\")\n",
        "            continue\n",
        "        \n",
        "        # Lists for storing data\n",
        "        X_images = []\n",
        "        y_emotions = []\n",
        "        frame_paths = []\n",
        "        \n",
        "        skipped = 0\n",
        "        found = 0\n",
        "        \n",
        "        for idx, row in tqdm(df.iterrows(), total=len(df), desc=f\"Processing {split_name}\"):\n",
        "            try:\n",
        "                if 'user_id' not in df.columns or 'timestamp' not in df.columns or 'Dominant_Emotion' not in df.columns:\n",
        "                    skipped += 1\n",
        "                    continue\n",
        "                \n",
        "                user_id = row['user_id']\n",
        "                timestamp = row['timestamp']\n",
        "                emotion = row['Dominant_Emotion']\n",
        "                \n",
        "                if pd.isna(user_id) or pd.isna(timestamp) or pd.isna(emotion):\n",
        "                    skipped += 1\n",
        "                    continue\n",
        "                \n",
        "                # Get sample number\n",
        "                sample_num = get_sample_number_from_user_id(user_id, user_id_mapping)\n",
        "                if sample_num is None:\n",
        "                    skipped += 1\n",
        "                    continue\n",
        "                \n",
        "                # Convert timestamp to frame filename\n",
        "                frame_name = format_timestamp_to_filename(timestamp)\n",
        "                if frame_name is None:\n",
        "                    skipped += 1\n",
        "                    continue\n",
        "                \n",
        "                # Find the image\n",
        "                img_path = find_image_in_sample_folder(images_dir, sample_num, frame_name)\n",
        "                \n",
        "                if img_path is None or not os.path.exists(img_path):\n",
        "                    skipped += 1\n",
        "                    continue\n",
        "                \n",
        "                # Copy image to emotion-specific directory\n",
        "                dest_path = os.path.join(split_img_dir, str(emotion), f\"{user_id}_{frame_name}\")\n",
        "                shutil.copy2(img_path, dest_path)\n",
        "                \n",
        "                # Read and preprocess image\n",
        "                img = cv2.imread(img_path)\n",
        "                if img is None:\n",
        "                    skipped += 1\n",
        "                    continue\n",
        "                \n",
        "                # Resize and normalize\n",
        "                img = cv2.resize(img, img_size)\n",
        "                img = img / 255.0  # Normalize to [0, 1]\n",
        "                \n",
        "                X_images.append(img)\n",
        "                y_emotions.append(emotion)\n",
        "                frame_paths.append(dest_path)\n",
        "                found += 1\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Error processing row {idx}: {e}\")\n",
        "                skipped += 1\n",
        "        \n",
        "        if not X_images:\n",
        "            print(f\"No valid image data found for {split_name}. Skipping.\")\n",
        "            continue\n",
        "        \n",
        "        # Convert to numpy arrays\n",
        "        X = np.array(X_images)\n",
        "        y = np.array(y_emotions)\n",
        "        \n",
        "        # Save as numpy arrays\n",
        "        np.save(os.path.join(cnn_output_dir, f\"X_{split_name}_images.npy\"), X)\n",
        "        np.save(os.path.join(cnn_output_dir, f\"y_{split_name}_images.npy\"), y)\n",
        "        \n",
        "        # Save frame paths for reference\n",
        "        paths_df = pd.DataFrame({\n",
        "            'path': frame_paths,\n",
        "            'emotion': y_emotions\n",
        "        })\n",
        "        paths_df.to_csv(os.path.join(cnn_output_dir, f\"{split_name}_image_paths.csv\"), index=False)\n",
        "        \n",
        "        # Print statistics\n",
        "        print(f\"  - Found images: {found}\")\n",
        "        print(f\"  - Skipped: {skipped}\")\n",
        "        print(f\"  - Shape of X_{split_name}_images: {X.shape}\")\n",
        "        \n",
        "        # Print emotion distribution\n",
        "        emotions, counts = np.unique(y, return_counts=True)\n",
        "        print(f\"  - Emotion distribution:\")\n",
        "        for emotion, count in zip(emotions, counts):\n",
        "            percent = count / len(y) * 100\n",
        "            print(f\"    {emotion}: {count} ({percent:.2f}%)\")\n",
        "    \n",
        "    print(f\"\\nCNN data preparation complete. Files saved to {cnn_output_dir}\")\n",
        "\n",
        "# Prepare CNN data\n",
        "if train_set is not None:\n",
        "    split_dir = os.path.join(FINAL_OUTPUT_DIR, \"Dataset_Split\")\n",
        "    prepare_cnn_data(split_dir, OUTPUT_BASE_DIR, FINAL_OUTPUT_DIR, SAMPLE_TO_USER_ID, IMG_SIZE)\n",
        "else:\n",
        "    print(\"No split data available for CNN preparation.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Prepare Data for LSTM (Landmarks)\n",
        "\n",
        "Prepare facial landmark data for LSTM training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_landmarks_with_regex(landmark_str):\n",
        "    \"\"\"Extract landmarks using regex from string.\"\"\"\n",
        "    if not isinstance(landmark_str, str):\n",
        "        return None\n",
        "    \n",
        "    # Pattern for finding x and y coordinates\n",
        "    x_pattern = r'\"_x\":([0-9.]+)'\n",
        "    y_pattern = r'\"_y\":([0-9.]+)'\n",
        "    \n",
        "    # Find all x and y values\n",
        "    x_matches = re.findall(x_pattern, landmark_str)\n",
        "    y_matches = re.findall(y_pattern, landmark_str)\n",
        "    \n",
        "    # Ensure equal number of x and y values\n",
        "    if len(x_matches) != len(y_matches):\n",
        "        return None\n",
        "    \n",
        "    # Combine x and y values in 1D array\n",
        "    flattened = []\n",
        "    for x, y in zip(x_matches, y_matches):\n",
        "        try:\n",
        "            flattened.append(float(x))\n",
        "            flattened.append(float(y))\n",
        "        except ValueError:\n",
        "            continue\n",
        "    \n",
        "    return flattened\n",
        "\n",
        "def prepare_lstm_data(split_dir, output_dir):\n",
        "    \"\"\"Prepare landmark data for LSTM.\"\"\"\n",
        "    print(\"Preparing data for LSTM...\")\n",
        "    \n",
        "    lstm_output_dir = os.path.join(output_dir, \"LSTM_Data\")\n",
        "    os.makedirs(lstm_output_dir, exist_ok=True)\n",
        "    \n",
        "    split_files = {\n",
        "        'train': os.path.join(split_dir, 'train_data.xlsx'),\n",
        "        'val': os.path.join(split_dir, 'val_data.xlsx'),\n",
        "        'test': os.path.join(split_dir, 'test_data.xlsx')\n",
        "    }\n",
        "    \n",
        "    for split_name, split_file in split_files.items():\n",
        "        if not os.path.exists(split_file):\n",
        "            print(f\"Warning: {split_file} not found. Skipping.\")\n",
        "            continue\n",
        "        \n",
        "        print(f\"\\nProcessing {split_name} data for LSTM...\")\n",
        "        df = pd.read_excel(split_file)\n",
        "        \n",
        "        # Check required columns\n",
        "        if 'landmarks' not in df.columns:\n",
        "            print(f\"Error: 'landmarks' column not found in {split_file}. Skipping.\")\n",
        "            continue\n",
        "            \n",
        "        if 'Dominant_Emotion' not in df.columns:\n",
        "            print(f\"Error: 'Dominant_Emotion' column not found in {split_file}. Skipping.\")\n",
        "            continue\n",
        "        \n",
        "        # Add challenge information if available\n",
        "        if 'page' in df.columns:\n",
        "            df['Challenge'] = df['page'].apply(extract_challenge_from_page)\n",
        "        \n",
        "        # Lists for storing processed data\n",
        "        X_landmarks = []\n",
        "        y_emotions = []\n",
        "        metadata = []\n",
        "        \n",
        "        skipped = 0\n",
        "        successful = 0\n",
        "        \n",
        "        for idx, row in df.iterrows():\n",
        "            try:\n",
        "                # Extract landmarks from JSON string\n",
        "                landmarks_str = row['landmarks']\n",
        "                if pd.isna(landmarks_str) or landmarks_str == \"\":\n",
        "                    skipped += 1\n",
        "                    continue\n",
        "                \n",
        "                # Try regex extraction first\n",
        "                flattened_landmarks = extract_landmarks_with_regex(landmarks_str)\n",
        "                \n",
        "                # If regex fails, try JSON parsing\n",
        "                if flattened_landmarks is None or len(flattened_landmarks) == 0:\n",
        "                    try:\n",
        "                        # Clean JSON string\n",
        "                        if isinstance(landmarks_str, str):\n",
        "                            landmarks_str = landmarks_str.replace('\\\\\"', '\"')\n",
        "                            if not landmarks_str.startswith('{'):\n",
        "                                landmarks_str = '{' + landmarks_str.split('{', 1)[1]\n",
        "                            if not landmarks_str.endswith('}'):\n",
        "                                landmarks_str = landmarks_str.rsplit('}', 1)[0] + '}'\n",
        "                        \n",
        "                        # Try JSON parsing\n",
        "                        try:\n",
        "                            landmarks_data = json.loads(landmarks_str)\n",
        "                        except json.JSONDecodeError:\n",
        "                            landmarks_str = landmarks_str.encode().decode('unicode_escape')\n",
        "                            landmarks_data = json.loads(landmarks_str)\n",
        "                        \n",
        "                        # Extract positions\n",
        "                        if isinstance(landmarks_data, dict) and '_positions' in landmarks_data:\n",
        "                            positions = landmarks_data['_positions']\n",
        "                            \n",
        "                            flattened_landmarks = []\n",
        "                            for point in positions:\n",
        "                                if isinstance(point, dict) and '_x' in point and '_y' in point:\n",
        "                                    flattened_landmarks.append(float(point['_x']))\n",
        "                                    flattened_landmarks.append(float(point['_y']))\n",
        "                                else:\n",
        "                                    raise ValueError(\"Invalid point structure\")\n",
        "                        else:\n",
        "                            raise ValueError(\"_positions not found in landmarks data\")\n",
        "                            \n",
        "                    except Exception as e:\n",
        "                        if skipped < 5:  # Only print first few errors\n",
        "                            print(f\"JSON parsing failed at row {idx}: {str(e)}\")\n",
        "                        skipped += 1\n",
        "                        continue\n",
        "                \n",
        "                # Process only if we have valid landmarks\n",
        "                if flattened_landmarks and len(flattened_landmarks) > 0:\n",
        "                    # Ensure consistent length (68 landmarks * 2 coordinates = 136)\n",
        "                    expected_length = 136\n",
        "                    \n",
        "                    if len(flattened_landmarks) < expected_length:\n",
        "                        # Pad with zeros\n",
        "                        flattened_landmarks.extend([0.0] * (expected_length - len(flattened_landmarks)))\n",
        "                    elif len(flattened_landmarks) > expected_length:\n",
        "                        # Truncate\n",
        "                        flattened_landmarks = flattened_landmarks[:expected_length]\n",
        "                    \n",
        "                    X_landmarks.append(flattened_landmarks)\n",
        "                    y_emotions.append(row['Dominant_Emotion'])\n",
        "                    \n",
        "                    # Add metadata\n",
        "                    meta = {\n",
        "                        'user_id': row['user_id'] if 'user_id' in df.columns else None,\n",
        "                        'timestamp': str(row['timestamp']) if 'timestamp' in df.columns else None,\n",
        "                        'Challenge': row.get('Challenge', None),\n",
        "                        'Confidence_Score': row.get('Confidence_Score', None)\n",
        "                    }\n",
        "                    metadata.append(meta)\n",
        "                    successful += 1\n",
        "                else:\n",
        "                    skipped += 1\n",
        "            except Exception as e:\n",
        "                if skipped < 5:  # Only print first few errors\n",
        "                    print(f\"Error processing row {idx}: {str(e)}\")\n",
        "                skipped += 1\n",
        "        \n",
        "        if not X_landmarks:\n",
        "            print(f\"No valid landmark data found in {split_file}. Skipping.\")\n",
        "            continue\n",
        "        \n",
        "        # Convert to numpy arrays\n",
        "        X = np.array(X_landmarks)\n",
        "        y = np.array(y_emotions)\n",
        "        \n",
        "        # Save as numpy arrays\n",
        "        np.save(os.path.join(lstm_output_dir, f\"X_{split_name}_landmarks.npy\"), X)\n",
        "        np.save(os.path.join(lstm_output_dir, f\"y_{split_name}.npy\"), y)\n",
        "        \n",
        "        # Save metadata\n",
        "        meta_df = pd.DataFrame(metadata)\n",
        "        meta_df.to_csv(os.path.join(lstm_output_dir, f\"{split_name}_metadata.csv\"), index=False)\n",
        "        \n",
        "        # Print statistics\n",
        "        print(f\"  - Successfully processed: {successful} samples\")\n",
        "        print(f\"  - Skipped: {skipped} samples\")\n",
        "        print(f\"  - Shape of X_{split_name}_landmarks: {X.shape}\")\n",
        "        print(f\"  - Shape of y_{split_name}: {y.shape}\")\n",
        "        \n",
        "        # Print emotion distribution\n",
        "        emotions, counts = np.unique(y, return_counts=True)\n",
        "        print(f\"  - Emotion distribution:\")\n",
        "        for emotion, count in zip(emotions, counts):\n",
        "            percent = count / len(y) * 100\n",
        "            print(f\"    {emotion}: {count} ({percent:.2f}%)\")\n",
        "    \n",
        "    print(f\"\\nLSTM data preparation complete. Files saved to {lstm_output_dir}\")\n",
        "\n",
        "# Prepare LSTM data\n",
        "if train_set is not None:\n",
        "    split_dir = os.path.join(FINAL_OUTPUT_DIR, \"Dataset_Split\")\n",
        "    prepare_lstm_data(split_dir, FINAL_OUTPUT_DIR)\n",
        "else:\n",
        "    print(\"No split data available for LSTM preparation.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Prepare Data for FCNN (Landmarks)\n",
        "\n",
        "Prepare facial landmark data for Fully Connected Neural Network (FCNN). The main difference from LSTM is that FCNN expects 2D input (samples × features) while LSTM expects 3D input (samples × timesteps × features)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_fcnn_data(split_dir, output_dir):\n",
        "    \"\"\"Prepare landmark data for FCNN (Fully Connected Neural Network).\"\"\"\n",
        "    print(\"Preparing data for FCNN...\")\n",
        "    \n",
        "    fcnn_output_dir = os.path.join(output_dir, \"FCNN_Data\")\n",
        "    os.makedirs(fcnn_output_dir, exist_ok=True)\n",
        "    \n",
        "    split_files = {\n",
        "        'train': os.path.join(split_dir, 'train_data.xlsx'),\n",
        "        'val': os.path.join(split_dir, 'val_data.xlsx'),\n",
        "        'test': os.path.join(split_dir, 'test_data.xlsx')\n",
        "    }\n",
        "    \n",
        "    for split_name, split_file in split_files.items():\n",
        "        if not os.path.exists(split_file):\n",
        "            print(f\"Warning: {split_file} not found. Skipping.\")\n",
        "            continue\n",
        "        \n",
        "        print(f\"\\nProcessing {split_name} data for FCNN...\")\n",
        "        df = pd.read_excel(split_file)\n",
        "        \n",
        "        # Check required columns\n",
        "        if 'landmarks' not in df.columns:\n",
        "            print(f\"Error: 'landmarks' column not found in {split_file}. Skipping.\")\n",
        "            continue\n",
        "            \n",
        "        if 'Dominant_Emotion' not in df.columns:\n",
        "            print(f\"Error: 'Dominant_Emotion' column not found in {split_file}. Skipping.\")\n",
        "            continue\n",
        "        \n",
        "        # Add challenge information if available\n",
        "        if 'page' in df.columns:\n",
        "            df['Challenge'] = df['page'].apply(extract_challenge_from_page)\n",
        "        \n",
        "        # Lists for storing processed data\n",
        "        X_landmarks = []\n",
        "        y_emotions = []\n",
        "        metadata = []\n",
        "        \n",
        "        skipped = 0\n",
        "        successful = 0\n",
        "        \n",
        "        for idx, row in df.iterrows():\n",
        "            try:\n",
        "                # Extract landmarks from JSON string\n",
        "                landmarks_str = row['landmarks']\n",
        "                if pd.isna(landmarks_str) or landmarks_str == \"\":\n",
        "                    skipped += 1\n",
        "                    continue\n",
        "                \n",
        "                # Try regex extraction first\n",
        "                flattened_landmarks = extract_landmarks_with_regex(landmarks_str)\n",
        "                \n",
        "                # If regex fails, try JSON parsing\n",
        "                if flattened_landmarks is None or len(flattened_landmarks) == 0:\n",
        "                    try:\n",
        "                        # Clean JSON string\n",
        "                        if isinstance(landmarks_str, str):\n",
        "                            landmarks_str = landmarks_str.replace('\\\\\"', '\"')\n",
        "                            if not landmarks_str.startswith('{'):\n",
        "                                landmarks_str = '{' + landmarks_str.split('{', 1)[1]\n",
        "                            if not landmarks_str.endswith('}'):\n",
        "                                landmarks_str = landmarks_str.rsplit('}', 1)[0] + '}'\n",
        "                        \n",
        "                        # Try JSON parsing\n",
        "                        try:\n",
        "                            landmarks_data = json.loads(landmarks_str)\n",
        "                        except json.JSONDecodeError:\n",
        "                            landmarks_str = landmarks_str.encode().decode('unicode_escape')\n",
        "                            landmarks_data = json.loads(landmarks_str)\n",
        "                        \n",
        "                        # Extract positions\n",
        "                        if isinstance(landmarks_data, dict) and '_positions' in landmarks_data:\n",
        "                            positions = landmarks_data['_positions']\n",
        "                            \n",
        "                            flattened_landmarks = []\n",
        "                            for point in positions:\n",
        "                                if isinstance(point, dict) and '_x' in point and '_y' in point:\n",
        "                                    flattened_landmarks.append(float(point['_x']))\n",
        "                                    flattened_landmarks.append(float(point['_y']))\n",
        "                                else:\n",
        "                                    raise ValueError(\"Invalid point structure\")\n",
        "                        else:\n",
        "                            raise ValueError(\"_positions not found in landmarks data\")\n",
        "                            \n",
        "                    except Exception as e:\n",
        "                        if skipped < 5:  # Only print first few errors\n",
        "                            print(f\"JSON parsing failed at row {idx}: {str(e)}\")\n",
        "                        skipped += 1\n",
        "                        continue\n",
        "                \n",
        "                # Process only if we have valid landmarks\n",
        "                if flattened_landmarks and len(flattened_landmarks) > 0:\n",
        "                    # Ensure consistent length (68 landmarks * 2 coordinates = 136)\n",
        "                    expected_length = 136\n",
        "                    \n",
        "                    if len(flattened_landmarks) < expected_length:\n",
        "                        # Pad with zeros\n",
        "                        flattened_landmarks.extend([0.0] * (expected_length - len(flattened_landmarks)))\n",
        "                    elif len(flattened_landmarks) > expected_length:\n",
        "                        # Truncate\n",
        "                        flattened_landmarks = flattened_landmarks[:expected_length]\n",
        "                    \n",
        "                    # For FCNN: Normalize the landmarks (optional but recommended)\n",
        "                    # You can uncomment the following lines for normalization:\n",
        "                    # landmarks_array = np.array(flattened_landmarks)\n",
        "                    # landmarks_array = (landmarks_array - landmarks_array.mean()) / (landmarks_array.std() + 1e-8)\n",
        "                    # flattened_landmarks = landmarks_array.tolist()\n",
        "                    \n",
        "                    X_landmarks.append(flattened_landmarks)\n",
        "                    y_emotions.append(row['Dominant_Emotion'])\n",
        "                    \n",
        "                    # Add metadata\n",
        "                    meta = {\n",
        "                        'user_id': row['user_id'] if 'user_id' in df.columns else None,\n",
        "                        'timestamp': str(row['timestamp']) if 'timestamp' in df.columns else None,\n",
        "                        'Challenge': row.get('Challenge', None),\n",
        "                        'Confidence_Score': row.get('Confidence_Score', None)\n",
        "                    }\n",
        "                    metadata.append(meta)\n",
        "                    successful += 1\n",
        "                else:\n",
        "                    skipped += 1\n",
        "            except Exception as e:\n",
        "                if skipped < 5:  # Only print first few errors\n",
        "                    print(f\"Error processing row {idx}: {str(e)}\")\n",
        "                skipped += 1\n",
        "        \n",
        "        if not X_landmarks:\n",
        "            print(f\"No valid landmark data found in {split_file}. Skipping.\")\n",
        "            continue\n",
        "        \n",
        "        # Convert to numpy arrays - this is the key difference for FCNN\n",
        "        # FCNN expects 2D input: (samples, features)\n",
        "        X = np.array(X_landmarks)  # Shape: (n_samples, 136)\n",
        "        y = np.array(y_emotions)   # Shape: (n_samples,)\n",
        "        \n",
        "        # Optional: Add feature engineering for FCNN\n",
        "        # You can add statistical features like mean, std, etc.\n",
        "        X_enhanced = X.copy()\n",
        "        \n",
        "        # Example feature engineering (uncomment if needed):\n",
        "        # # Calculate statistical features for each sample\n",
        "        # x_coords = X[:, ::2]  # Even indices are x coordinates\n",
        "        # y_coords = X[:, 1::2]  # Odd indices are y coordinates\n",
        "        # \n",
        "        # # Add statistical features\n",
        "        # x_mean = np.mean(x_coords, axis=1, keepdims=True)\n",
        "        # y_mean = np.mean(y_coords, axis=1, keepdims=True)\n",
        "        # x_std = np.std(x_coords, axis=1, keepdims=True)\n",
        "        # y_std = np.std(y_coords, axis=1, keepdims=True)\n",
        "        # \n",
        "        # # Concatenate original features with statistical features\n",
        "        # X_enhanced = np.concatenate([X, x_mean, y_mean, x_std, y_std], axis=1)\n",
        "        \n",
        "        # Save as numpy arrays\n",
        "        np.save(os.path.join(fcnn_output_dir, f\"X_{split_name}_landmarks.npy\"), X_enhanced)\n",
        "        np.save(os.path.join(fcnn_output_dir, f\"y_{split_name}.npy\"), y)\n",
        "        \n",
        "        # Save original landmarks without enhancement for comparison\n",
        "        np.save(os.path.join(fcnn_output_dir, f\"X_{split_name}_landmarks_original.npy\"), X)\n",
        "        \n",
        "        # Save metadata\n",
        "        meta_df = pd.DataFrame(metadata)\n",
        "        meta_df.to_csv(os.path.join(fcnn_output_dir, f\"{split_name}_metadata.csv\"), index=False)\n",
        "        \n",
        "        # Print statistics\n",
        "        print(f\"  - Successfully processed: {successful} samples\")\n",
        "        print(f\"  - Skipped: {skipped} samples\")\n",
        "        print(f\"  - Shape of X_{split_name}_landmarks: {X_enhanced.shape}\")\n",
        "        print(f\"  - Shape of y_{split_name}: {y.shape}\")\n",
        "        print(f\"  - Features per sample: {X_enhanced.shape[1]}\")\n",
        "        \n",
        "        # Print emotion distribution\n",
        "        emotions, counts = np.unique(y, return_counts=True)\n",
        "        print(f\"  - Emotion distribution:\")\n",
        "        for emotion, count in zip(emotions, counts):\n",
        "            percent = count / len(y) * 100\n",
        "            print(f\"    {emotion}: {count} ({percent:.2f}%)\")\n",
        "    \n",
        "    print(f\"\\nFCNN data preparation complete. Files saved to {fcnn_output_dir}\")\n",
        "    print(\"\\nFiles created for FCNN:\")\n",
        "    print(\"  - X_[split]_landmarks.npy: Enhanced features (recommended)\")\n",
        "    print(\"  - X_[split]_landmarks_original.npy: Original 136 features\")\n",
        "    print(\"  - y_[split].npy: Emotion labels\")\n",
        "    print(\"  - [split]_metadata.csv: Additional information\")\n",
        "\n",
        "# Prepare FCNN data\n",
        "if train_set is not None:\n",
        "    split_dir = os.path.join(FINAL_OUTPUT_DIR, \"Dataset_Split\")\n",
        "    prepare_fcnn_data(split_dir, FINAL_OUTPUT_DIR)\n",
        "else:\n",
        "    print(\"No split data available for FCNN preparation.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary and Final Report\n",
        "\n",
        "Generate a comprehensive summary of the preprocessing pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_preprocessing_report(output_dir):\n",
        "    \"\"\"Generate a comprehensive preprocessing report.\"\"\"\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"PREPROCESSING PIPELINE COMPLETED\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    report_lines = []\n",
        "    report_lines.append(\"Emotion Recognition Data Preprocessing Report\")\n",
        "    report_lines.append(\"=\"*50)\n",
        "    report_lines.append(\"\")\n",
        "    \n",
        "    # Check what files were created\n",
        "    files_created = []\n",
        "    \n",
        "    # Check main outputs\n",
        "    main_files = [\n",
        "        (\"Cleaned Data\", os.path.join(OUTPUT_BASE_DIR, \"all_cleaned_data.xlsx\")),\n",
        "        (\"Labeled Data\", os.path.join(FINAL_OUTPUT_DIR, \"labeled_data.xlsx\")),\n",
        "        (\"Train Set\", os.path.join(FINAL_OUTPUT_DIR, \"Dataset_Split\", \"train_data.xlsx\")),\n",
        "        (\"Validation Set\", os.path.join(FINAL_OUTPUT_DIR, \"Dataset_Split\", \"val_data.xlsx\")),\n",
        "        (\"Test Set\", os.path.join(FINAL_OUTPUT_DIR, \"Dataset_Split\", \"test_data.xlsx\"))\n",
        "    ]\n",
        "    \n",
        "    for name, path in main_files:\n",
        "        if os.path.exists(path):\n",
        "            try:\n",
        "                df = pd.read_excel(path)\n",
        "                files_created.append(f\"{name}: {len(df)} records\")\n",
        "                report_lines.append(f\"{name}: {len(df)} records\")\n",
        "            except:\n",
        "                files_created.append(f\"{name}: File exists but couldn't read\")\n",
        "                report_lines.append(f\"{name}: File exists but couldn't read\")\n",
        "        else:\n",
        "            report_lines.append(f\"{name}: Not created\")\n",
        "    \n",
        "    report_lines.append(\"\")\n",
        "    \n",
        "    # Check CNN data\n",
        "    cnn_dir = os.path.join(FINAL_OUTPUT_DIR, \"CNN_Data\")\n",
        "    if os.path.exists(cnn_dir):\n",
        "        report_lines.append(\"CNN Data:\")\n",
        "        for split in ['train', 'val', 'test']:\n",
        "            X_file = os.path.join(cnn_dir, f\"X_{split}_images.npy\")\n",
        "            y_file = os.path.join(cnn_dir, f\"y_{split}_images.npy\")\n",
        "            if os.path.exists(X_file) and os.path.exists(y_file):\n",
        "                try:\n",
        "                    X = np.load(X_file)\n",
        "                    y = np.load(y_file)\n",
        "                    report_lines.append(f\"  {split.title()}: {len(X)} images, shape {X.shape}\")\n",
        "                    files_created.append(f\"CNN {split}: {len(X)} images\")\n",
        "                except:\n",
        "                    report_lines.append(f\"  {split.title()}: Files exist but couldn't load\")\n",
        "            else:\n",
        "                report_lines.append(f\"  {split.title()}: Not created\")\n",
        "    else:\n",
        "        report_lines.append(\"CNN Data: Not created\")\n",
        "    \n",
        "    report_lines.append(\"\")\n",
        "    \n",
        "    # Check LSTM data\n",
        "    lstm_dir = os.path.join(FINAL_OUTPUT_DIR, \"LSTM_Data\")\n",
        "    if os.path.exists(lstm_dir):\n",
        "        report_lines.append(\"LSTM Data:\")\n",
        "        for split in ['train', 'val', 'test']:\n",
        "            X_file = os.path.join(lstm_dir, f\"X_{split}_landmarks.npy\")\n",
        "            y_file = os.path.join(lstm_dir, f\"y_{split}.npy\")\n",
        "            if os.path.exists(X_file) and os.path.exists(y_file):\n",
        "                try:\n",
        "                    X = np.load(X_file)\n",
        "                    y = np.load(y_file)\n",
        "                    report_lines.append(f\"  {split.title()}: {len(X)} landmarks, shape {X.shape}\")\n",
        "                    files_created.append(f\"LSTM {split}: {len(X)} landmarks\")\n",
        "                except:\n",
        "                    report_lines.append(f\"  {split.title()}: Files exist but couldn't load\")\n",
        "            else:\n",
        "                report_lines.append(f\"  {split.title()}: Not created\")\n",
        "    else:\n",
        "        report_lines.append(\"LSTM Data: Not created\")\n",
        "    \n",
        "    report_lines.append(\"\")\n",
        "    \n",
        "    # Check FCNN data\n",
        "    fcnn_dir = os.path.join(FINAL_OUTPUT_DIR, \"FCNN_Data\")\n",
        "    if os.path.exists(fcnn_dir):\n",
        "        report_lines.append(\"FCNN Data:\")\n",
        "        for split in ['train', 'val', 'test']:\n",
        "            X_file = os.path.join(fcnn_dir, f\"X_{split}_landmarks.npy\")\n",
        "            y_file = os.path.join(fcnn_dir, f\"y_{split}.npy\")\n",
        "            if os.path.exists(X_file) and os.path.exists(y_file):\n",
        "                try:\n",
        "                    X = np.load(X_file)\n",
        "                    y = np.load(y_file)\n",
        "                    report_lines.append(f\"  {split.title()}: {len(X)} landmarks, shape {X.shape}\")\n",
        "                    files_created.append(f\"FCNN {split}: {len(X)} landmarks\")\n",
        "                except:\n",
        "                    report_lines.append(f\"  {split.title()}: Files exist but couldn't load\")\n",
        "            else:\n",
        "                report_lines.append(f\"  {split.title()}: Not created\")\n",
        "    else:\n",
        "        report_lines.append(\"FCNN Data: Not created\")\n",
        "    \n",
        "    report_lines.append(\"\")\n",
        "    report_lines.append(\"Output Directories:\")\n",
        "    report_lines.append(f\"  Cleaned Data: {OUTPUT_BASE_DIR}\")\n",
        "    report_lines.append(f\"  Final Dataset: {FINAL_OUTPUT_DIR}\")\n",
        "    report_lines.append(f\"  CNN Data: {os.path.join(FINAL_OUTPUT_DIR, 'CNN_Data')}\")\n",
        "    report_lines.append(f\"  LSTM Data: {os.path.join(FINAL_OUTPUT_DIR, 'LSTM_Data')}\")\n",
        "    report_lines.append(f\"  FCNN Data: {os.path.join(FINAL_OUTPUT_DIR, 'FCNN_Data')}\")\n",
        "    \n",
        "    # Save report\n",
        "    report_path = os.path.join(FINAL_OUTPUT_DIR, \"preprocessing_report.txt\")\n",
        "    with open(report_path, 'w') as f:\n",
        "        f.write('\\n'.join(report_lines))\n",
        "    \n",
        "    # Print summary\n",
        "    for line in report_lines:\n",
        "        print(line)\n",
        "    \n",
        "    print(f\"\\nDetailed report saved to: {report_path}\")\n",
        "    print(\"\\nPreprocessing pipeline completed successfully!\")\n",
        "    print(\"\\nNext Steps:\")\n",
        "    print(\"1. Use CNN_Data for training image-based emotion recognition models\")\n",
        "    print(\"2. Use LSTM_Data for training sequence-based landmark emotion recognition models\")\n",
        "    print(\"3. Use FCNN_Data for training fully-connected landmark emotion recognition models\")\n",
        "    print(\"4. Compare performance between CNN (images) vs FCNN (landmarks) vs LSTM (sequences)\")\n",
        "    print(\"5. Consider ensemble methods combining multiple approaches\")\n",
        "\n",
        "# Generate final report\n",
        "generate_preprocessing_report(FINAL_OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration Notes\n",
        "\n",
        "**Important:** Before running this notebook, ensure you:\n",
        "\n",
        "1. **Update the Configuration Section** with your actual file paths\n",
        "2. **Verify the Sample-to-User-ID Mapping** matches your data\n",
        "3. **Check Directory Structure:** \n",
        "   - Base directory should contain folders named \"Sample 1\", \"Sample 2\", etc.\n",
        "   - Each sample folder should have a \"frames\" subdirectory with images\n",
        "4. **Excel File Format:** Should contain columns like 'user_id', 'timestamp', 'landmarks', emotion columns, etc.\n",
        "\n",
        "**Key Changes from Original Scripts:**\n",
        "- Data is now organized per sample (not per challenge)\n",
        "- Simplified directory structure\n",
        "- Combined preprocessing pipeline\n",
        "- Better error handling and progress reporting\n",
        "- Comprehensive final report generation\n",
        "\n",
        "**Output Structure:**\n",
        "```\n",
        "Final_Dataset/\n",
        "├── labeled_data.xlsx\n",
        "├── Dataset_Split/\n",
        "│   ├── train_data.xlsx\n",
        "│   ├── val_data.xlsx\n",
        "│   └── test_data.xlsx\n",
        "├── CNN_Data/\n",
        "│   ├── X_train_images.npy\n",
        "│   ├── y_train_images.npy\n",
        "│   ├── train_images/\n",
        "│   └── ...\n",
        "├── LSTM_Data/\n",
        "│   ├── X_train_landmarks.npy\n",
        "│   ├── y_train.npy\n",
        "│   └── ...\n",
        "├── FCNN_Data/\n",
        "│   ├── X_train_landmarks.npy (enhanced)\n",
        "│   ├── X_train_landmarks_original.npy\n",
        "│   ├── y_train.npy\n",
        "│   └── ...\n",
        "└── preprocessing_report.txt\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}