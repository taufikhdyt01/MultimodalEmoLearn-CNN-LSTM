{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Experiments\n",
    "\n",
    "**Tujuan notebook ini:**\n",
    "1. Test berbagai hyperparameter dengan epochs rendah\n",
    "2. Bandingkan learning rates, batch sizes, dan architectures\n",
    "3. Find optimal configuration sebelum full training\n",
    "4. Validate fusion strategies\n",
    "\n",
    "**‚ö†Ô∏è Jalankan notebook ini SETELAH validation notebook dan SEBELUM full training!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Advanced TensorFlow GPU Setup for AMD RX 6600 LE\n",
    "import tensorflow as tf\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# Comprehensive GPU setup for AMD on Windows\n",
    "def setup_amd_gpu():\n",
    "    \"\"\"Setup AMD GPU with DirectML for optimal performance\"\"\"\n",
    "    try:\n",
    "        # Check for GPU availability\n",
    "        from tensorflow.python.client import device_lib\n",
    "        devices = device_lib.list_local_devices()\n",
    "        gpu_devices = [d for d in devices if d.device_type == 'GPU']\n",
    "        \n",
    "        if gpu_devices:\n",
    "            print(f\"\\nüéÆ AMD RX 6600 LE GPU SETUP:\")\n",
    "            for i, gpu in enumerate(gpu_devices):\n",
    "                print(f\"   GPU {i}: {gpu.name}\")\n",
    "                print(f\"   Memory: ~8GB VRAM (RX 6600 LE)\")\n",
    "            \n",
    "            # Configure memory growth\n",
    "            gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "            if gpus:\n",
    "                try:\n",
    "                    for gpu in gpus:\n",
    "                        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "                    print(\"   ‚úÖ Memory growth enabled\")\n",
    "                except RuntimeError as e:\n",
    "                    print(f\"   ‚ö†Ô∏è Memory setup warning: {e}\")\n",
    "            \n",
    "            # Set memory limit to prevent OOM (use ~80% of VRAM)\n",
    "            try:\n",
    "                for gpu in gpus:\n",
    "                    tf.config.experimental.set_memory_limit(gpu, 6400)  # ~6.4GB of 8GB\n",
    "                print(\"   ‚úÖ Memory limit set to 6.4GB\")\n",
    "            except:\n",
    "                print(\"   ‚ö†Ô∏è Could not set memory limit (may not be needed)\")\n",
    "            \n",
    "            # Enable mixed precision for better performance (if supported)\n",
    "            try:\n",
    "                from tensorflow.keras import mixed_precision\n",
    "                policy = mixed_precision.Policy('mixed_float16')\n",
    "                mixed_precision.set_global_policy(policy)\n",
    "                print(\"   ‚úÖ Mixed precision enabled\")\n",
    "            except:\n",
    "                print(\"   ‚ö†Ô∏è Mixed precision not available\")\n",
    "            \n",
    "            # Configure for optimal performance\n",
    "            tf.config.optimizer.set_jit(True)  # Enable XLA compilation\n",
    "            tf.config.set_soft_device_placement(True)\n",
    "            \n",
    "            print(f\"   ‚úÖ GPU optimization completed!\")\n",
    "            \n",
    "            # Test GPU functionality\n",
    "            print(f\"\\nüîç GPU FUNCTIONALITY TEST:\")\n",
    "            with tf.device('/GPU:0'):\n",
    "                # Simple tensor operation\n",
    "                a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "                b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "                c = tf.matmul(a, b)\n",
    "                print(f\"   ‚úÖ Matrix multiplication test passed\")\n",
    "            \n",
    "            return True, len(gpu_devices)\n",
    "            \n",
    "        else:\n",
    "            print(\"\\n‚ö†Ô∏è NO GPU DETECTED!\")\n",
    "            print(\"üí° For AMD RX 6600 LE support on Windows:\")\n",
    "            print(\"   1. Install: pip uninstall tensorflow\")\n",
    "            print(\"   2. Install: pip install tensorflow-directml\")\n",
    "            print(\"   3. Restart kernel and try again\")\n",
    "            return False, 0\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå GPU setup failed: {e}\")\n",
    "        print(\"üí° Falling back to CPU mode\")\n",
    "        return False, 0\n",
    "\n",
    "# Run GPU setup\n",
    "gpu_available, num_gpus = setup_amd_gpu()\n",
    "\n",
    "# Import remaining TensorFlow components\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, Dropout, BatchNormalization, Input, concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(f\"\\n‚úÖ Libraries imported successfully!\")\n",
    "print(f\"üéÆ GPU Status: {'Enabled' if gpu_available else 'Disabled (CPU only)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. üìÅ Load Validation Results\n",
    "\n",
    "Load hasil dari notebook sebelumnya dan data yang sudah divalidasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load validation results\n",
    "try:\n",
    "    with open('validation_results.pkl', 'rb') as f:\n",
    "        validation_data = pickle.load(f)\n",
    "    \n",
    "    print(\"‚úÖ Validation results loaded successfully!\")\n",
    "    print(f\"Validation timestamp: {validation_data['timestamp']}\")\n",
    "    print(f\"Number of classes: {validation_data['label_info']['num_classes']}\")\n",
    "    \n",
    "    # Extract info\n",
    "    label_map = validation_data['label_info']['label_map']\n",
    "    num_classes = validation_data['label_info']['num_classes']\n",
    "    target_names = validation_data['label_info']['target_names']\n",
    "    \n",
    "    print(f\"Classes: {target_names}\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå validation_results.pkl not found!\")\n",
    "    print(\"Please run the validation notebook first.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load actual data - adjust paths as needed\n",
    "BASE_PATH = 'D:/research/2025_iris_taufik/MultimodalEmoLearn-CNN-LSTM/data/'\n",
    "\n",
    "print(\"Loading data...\")\n",
    "X_train_images = np.load(BASE_PATH + 'images/X_train_images.npy')\n",
    "X_val_images = np.load(BASE_PATH + 'images/X_val_images.npy')\n",
    "X_test_images = np.load(BASE_PATH + 'images/X_test_images.npy')\n",
    "\n",
    "X_train_landmarks = np.load(BASE_PATH + 'landmarks/X_train_landmarks.npy')\n",
    "X_val_landmarks = np.load(BASE_PATH + 'landmarks/X_val_landmarks.npy')\n",
    "X_test_landmarks = np.load(BASE_PATH + 'landmarks/X_test_landmarks.npy')\n",
    "\n",
    "y_train = np.load(BASE_PATH + 'images/y_train_images.npy')\n",
    "y_val = np.load(BASE_PATH + 'images/y_val_images.npy')\n",
    "y_test = np.load(BASE_PATH + 'images/y_test_images.npy')\n",
    "\n",
    "# Convert labels\n",
    "y_train_num = np.array([label_map[label] for label in y_train])\n",
    "y_val_num = np.array([label_map[label] for label in y_val])\n",
    "y_test_num = np.array([label_map[label] for label in y_test])\n",
    "\n",
    "y_train_onehot = to_categorical(y_train_num, num_classes)\n",
    "y_val_onehot = to_categorical(y_val_num, num_classes)\n",
    "y_test_onehot = to_categorical(y_test_num, num_classes)\n",
    "\n",
    "print(f\"‚úÖ Data loaded successfully!\")\n",
    "print(f\"Training samples: {X_train_images.shape[0]}\")\n",
    "print(f\"Validation samples: {X_val_images.shape[0]}\")\n",
    "print(f\"Test samples: {X_test_images.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. üîß Define Model Architectures\n",
    "\n",
    "Definisikan berbagai variasi model untuk testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn_model(input_shape, num_classes, complexity='medium', dropout_rate=0.25):\n",
    "    \"\"\"Build CNN model with different complexity levels\"\"\"\n",
    "    \n",
    "    if complexity == 'simple':\n",
    "        model = Sequential([\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten(),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "    \n",
    "    elif complexity == 'medium':\n",
    "        model = Sequential([\n",
    "            Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            \n",
    "            Conv2D(64, (3, 3), activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            \n",
    "            Conv2D(128, (3, 3), activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            \n",
    "            Flatten(),\n",
    "            Dense(256, activation='relu'),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(128, activation='relu'),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "    \n",
    "    elif complexity == 'complex':\n",
    "        model = Sequential([\n",
    "            Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=input_shape),\n",
    "            BatchNormalization(),\n",
    "            Conv2D(32, (3, 3), padding='same', activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Dropout(dropout_rate),\n",
    "            \n",
    "            Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Dropout(dropout_rate),\n",
    "            \n",
    "            Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Dropout(dropout_rate),\n",
    "            \n",
    "            Flatten(),\n",
    "            Dense(512, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.5),\n",
    "            Dense(256, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(0.5),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def build_landmark_model(input_shape, num_classes, complexity='medium', dropout_rate=0.3):\n",
    "    \"\"\"Build landmark model with different complexity levels\"\"\"\n",
    "    \n",
    "    if complexity == 'simple':\n",
    "        model = Sequential([\n",
    "            Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(64, activation='relu'),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "    \n",
    "    elif complexity == 'medium':\n",
    "        model = Sequential([\n",
    "            Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "            BatchNormalization(),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(256, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(128, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "    \n",
    "    elif complexity == 'complex':\n",
    "        model = Sequential([\n",
    "            Dense(256, activation='relu', input_shape=(input_shape,)),\n",
    "            BatchNormalization(),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(512, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(256, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(128, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(dropout_rate),\n",
    "            Dense(num_classes, activation='softmax')\n",
    "        ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "print(\"‚úÖ Model architectures defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. üß™ Hyperparameter Experiments\n",
    "\n",
    "Test berbagai kombinasi hyperparameters dengan epochs rendah untuk cepat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment configurations optimized for RX 6600 LE\n",
    "experiment_configs = {\n",
    "    'learning_rates': [0.001, 0.0001, 0.00001],\n",
    "    'batch_sizes': [32, 16, 8] if gpu_available else [16, 8, 4],  # Smaller batches for 8GB VRAM\n",
    "    'complexities': ['simple', 'medium'],  # Skip complex untuk conserve VRAM\n",
    "    'dropout_rates': [0.2, 0.3, 0.5]\n",
    "}\n",
    "\n",
    "# Adjust experiment size based on GPU availability\n",
    "if gpu_available:\n",
    "    # With GPU, can handle more data\n",
    "    experiment_size = min(3000, X_train_images.shape[0])\n",
    "    val_size = min(800, X_val_images.shape[0])\n",
    "    print(f\"üéÆ GPU Mode: Using larger experiment dataset\")\n",
    "else:\n",
    "    # CPU mode - use smaller dataset\n",
    "    experiment_size = min(1500, X_train_images.shape[0])\n",
    "    val_size = min(400, X_val_images.shape[0])\n",
    "    print(f\"üíª CPU Mode: Using smaller experiment dataset\")\n",
    "\n",
    "X_train_exp = X_train_images[:experiment_size]\n",
    "X_train_landmarks_exp = X_train_landmarks[:experiment_size]\n",
    "y_train_exp = y_train_onehot[:experiment_size]\n",
    "\n",
    "X_val_exp = X_val_images[:val_size]\n",
    "X_val_landmarks_exp = X_val_landmarks[:val_size]\n",
    "y_val_exp = y_val_onehot[:val_size]\n",
    "\n",
    "print(f\"\\nüß™ EXPERIMENT SETUP:\")\n",
    "print(f\"   Training samples: {experiment_size:,} ({experiment_size/X_train_images.shape[0]*100:.1f}% of full dataset)\")\n",
    "print(f\"   Validation samples: {val_size:,}\")\n",
    "print(f\"   Device: {'GPU (RX 6600 LE)' if gpu_available else 'CPU'}\")\n",
    "print(f\"   Batch sizes to test: {experiment_configs['batch_sizes']}\")\n",
    "\n",
    "# Storage for results\n",
    "experiment_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to run single experiment with GPU optimization\n",
    "def run_experiment(model_type, learning_rate, batch_size, complexity, dropout_rate, epochs=5):\n",
    "    \"\"\"Run single experiment with given parameters, optimized for RX 6600 LE\"\"\"\n",
    "    \n",
    "    device_name = 'GPU (RX 6600 LE)' if gpu_available else 'CPU'\n",
    "    print(f\"\\nüî¨ Testing {model_type} on {device_name}\")\n",
    "    print(f\"   LR:{learning_rate}, BS:{batch_size}, Complexity:{complexity}, Dropout:{dropout_rate}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # Force GPU device placement if available\n",
    "        device_context = '/GPU:0' if gpu_available else '/CPU:0'\n",
    "        \n",
    "        with tf.device(device_context):\n",
    "            if model_type == 'cnn':\n",
    "                model = build_cnn_model(X_train_exp.shape[1:], num_classes, complexity, dropout_rate)\n",
    "                X_train_model = X_train_exp\n",
    "                X_val_model = X_val_exp\n",
    "            elif model_type == 'landmark':\n",
    "                model = build_landmark_model(X_train_landmarks_exp.shape[1], num_classes, complexity, dropout_rate)\n",
    "                X_train_model = X_train_landmarks_exp\n",
    "                X_val_model = X_val_landmarks_exp\n",
    "            \n",
    "            # Compile model with appropriate optimizer settings\n",
    "            optimizer = Adam(learning_rate=learning_rate)\n",
    "            if gpu_available:\n",
    "                # Use mixed precision loss scaling if available\n",
    "                try:\n",
    "                    optimizer = tf.keras.mixed_precision.LossScaleOptimizer(optimizer)\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            model.compile(\n",
    "                optimizer=optimizer,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "            \n",
    "            # Adjust epochs based on device\n",
    "            actual_epochs = epochs if gpu_available else max(3, epochs-2)  # Fewer epochs on CPU\n",
    "            \n",
    "            # Create callbacks for memory management\n",
    "            callbacks = []\n",
    "            if gpu_available:\n",
    "                # Early stopping to prevent memory issues\n",
    "                callbacks.append(EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True))\n",
    "            \n",
    "            # Train model with memory-efficient settings\n",
    "            history = model.fit(\n",
    "                X_train_model, y_train_exp,\n",
    "                batch_size=batch_size,\n",
    "                epochs=actual_epochs,\n",
    "                validation_data=(X_val_model, y_val_exp),\n",
    "                verbose=0,\n",
    "                callbacks=callbacks\n",
    "            )\n",
    "            \n",
    "            # Get results\n",
    "            final_train_acc = history.history['accuracy'][-1]\n",
    "            final_val_acc = history.history['val_accuracy'][-1]\n",
    "            final_train_loss = history.history['loss'][-1]\n",
    "            final_val_loss = history.history['val_loss'][-1]\n",
    "            \n",
    "            # Calculate overfitting indicator\n",
    "            overfitting = final_train_acc - final_val_acc\n",
    "            \n",
    "            experiment_time = time.time() - start_time\n",
    "            \n",
    "            # Memory usage estimation\n",
    "            memory_usage = 'Unknown'\n",
    "            if gpu_available:\n",
    "                try:\n",
    "                    # Rough estimation based on model size and batch size\n",
    "                    model_params = model.count_params()\n",
    "                    estimated_memory_mb = (model_params * 4 * batch_size) / (1024 * 1024)  # Rough estimate\n",
    "                    memory_usage = f\"~{estimated_memory_mb:.0f}MB\"\n",
    "                except:\n",
    "                    pass\n",
    "            \n",
    "            result = {\n",
    "                'model_type': model_type,\n",
    "                'learning_rate': learning_rate,\n",
    "                'batch_size': batch_size,\n",
    "                'complexity': complexity,\n",
    "                'dropout_rate': dropout_rate,\n",
    "                'epochs': actual_epochs,\n",
    "                'final_train_acc': final_train_acc,\n",
    "                'final_val_acc': final_val_acc,\n",
    "                'final_train_loss': final_train_loss,\n",
    "                'final_val_loss': final_val_loss,\n",
    "                'overfitting': overfitting,\n",
    "                'experiment_time': experiment_time,\n",
    "                'parameters': model.count_params(),\n",
    "                'device': device_name,\n",
    "                'memory_usage': memory_usage,\n",
    "                'status': 'success'\n",
    "            }\n",
    "            \n",
    "            print(f\"   ‚úÖ Val Acc: {final_val_acc:.4f}, Overfitting: {overfitting:.4f}, Time: {experiment_time:.1f}s\")\n",
    "            if gpu_available:\n",
    "                print(f\"   üíæ Est. Memory: {memory_usage}\")\n",
    "            \n",
    "            # Clear memory\n",
    "            del model\n",
    "            if gpu_available:\n",
    "                tf.keras.backend.clear_session()\n",
    "            \n",
    "            return result\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Error: {str(e)}\")\n",
    "        \n",
    "        # Try to diagnose GPU memory issues\n",
    "        if gpu_available and 'memory' in str(e).lower():\n",
    "            print(f\"   üí° GPU memory issue detected. Try smaller batch size.\")\n",
    "        \n",
    "        # Clear memory on error\n",
    "        if gpu_available:\n",
    "            tf.keras.backend.clear_session()\n",
    "        \n",
    "        return {\n",
    "            'model_type': model_type,\n",
    "            'learning_rate': learning_rate,\n",
    "            'batch_size': batch_size,\n",
    "            'complexity': complexity,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'device': device_name,\n",
    "            'status': 'failed',\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ GPU-optimized experiment function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CNN experiments with GPU optimization\n",
    "print(f\"üñºÔ∏è RUNNING CNN EXPERIMENTS ON {'GPU (RX 6600 LE)' if gpu_available else 'CPU'}...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cnn_results = []\n",
    "experiment_count = 0\n",
    "total_experiments = len(experiment_configs['learning_rates']) * len(experiment_configs['batch_sizes']) * len(experiment_configs['complexities'])\n",
    "\n",
    "successful_experiments = 0\n",
    "failed_experiments = 0\n",
    "\n",
    "for lr in experiment_configs['learning_rates']:\n",
    "    for bs in experiment_configs['batch_sizes']:\n",
    "        for complexity in experiment_configs['complexities']:\n",
    "            experiment_count += 1\n",
    "            print(f\"\\nüìä CNN Experiment {experiment_count}/{total_experiments}\")\n",
    "            \n",
    "            # Use optimal dropout for complexity\n",
    "            dropout = 0.25 if complexity == 'simple' else 0.3\n",
    "            \n",
    "            # Adjust epochs based on GPU availability and batch size\n",
    "            if gpu_available:\n",
    "                epochs = 10 if bs >= 16 else 8  # More epochs with larger batches\n",
    "            else:\n",
    "                epochs = 6 if bs >= 8 else 5    # Fewer epochs on CPU\n",
    "            \n",
    "            result = run_experiment('cnn', lr, bs, complexity, dropout, epochs=epochs)\n",
    "            cnn_results.append(result)\n",
    "            experiment_results.append(result)\n",
    "            \n",
    "            if result['status'] == 'success':\n",
    "                successful_experiments += 1\n",
    "            else:\n",
    "                failed_experiments += 1\n",
    "                # If memory error with GPU, suggest smaller batch size\n",
    "                if gpu_available and 'memory' in result.get('error', '').lower():\n",
    "                    print(f\"   üí° Try batch size {bs//2} for this configuration\")\n",
    "            \n",
    "            # Memory cleanup between experiments\n",
    "            if gpu_available and experiment_count % 3 == 0:\n",
    "                print(f\"   üßπ Cleaning GPU memory...\")\n",
    "                tf.keras.backend.clear_session()\n",
    "                time.sleep(1)  # Brief pause for memory cleanup\n",
    "\n",
    "print(f\"\\n‚úÖ CNN experiments completed!\")\n",
    "print(f\"   Successful: {successful_experiments}/{total_experiments}\")\n",
    "print(f\"   Failed: {failed_experiments}/{total_experiments}\")\n",
    "if gpu_available:\n",
    "    print(f\"   Device: AMD RX 6600 LE GPU\")\n",
    "else:\n",
    "    print(f\"   Device: CPU (consider installing tensorflow-directml)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Landmark experiments\n",
    "print(\"\\nüéØ RUNNING LANDMARK EXPERIMENTS...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "landmark_results = []\n",
    "experiment_count = 0\n",
    "\n",
    "for lr in experiment_configs['learning_rates']:\n",
    "    for bs in experiment_configs['batch_sizes']:\n",
    "        for complexity in experiment_configs['complexities']:\n",
    "            experiment_count += 1\n",
    "            print(f\"\\nExperiment {experiment_count}/{total_experiments}\")\n",
    "            \n",
    "            # Use default dropout for landmarks\n",
    "            dropout = 0.3 if complexity == 'simple' else 0.4\n",
    "            \n",
    "            result = run_experiment('landmark', lr, bs, complexity, dropout, epochs=10)\n",
    "            landmark_results.append(result)\n",
    "            experiment_results.append(result)\n",
    "\n",
    "print(f\"\\n‚úÖ Landmark experiments completed! {len([r for r in landmark_results if r['status'] == 'success'])}/{len(landmark_results)} successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. üìä Analyze Results\n",
    "\n",
    "Analisis hasil eksperimen untuk menemukan hyperparameter terbaik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to DataFrame for analysis\n",
    "successful_results = [r for r in experiment_results if r['status'] == 'success']\n",
    "df_results = pd.DataFrame(successful_results)\n",
    "\n",
    "if len(df_results) > 0:\n",
    "    print(f\"üìä Analyzing {len(df_results)} successful experiments...\")\n",
    "    \n",
    "    # Best results per model type\n",
    "    print(\"\\nüèÜ BEST RESULTS PER MODEL TYPE:\")\n",
    "    for model_type in df_results['model_type'].unique():\n",
    "        model_results = df_results[df_results['model_type'] == model_type]\n",
    "        best_result = model_results.loc[model_results['final_val_acc'].idxmax()]\n",
    "        \n",
    "        print(f\"\\n{model_type.upper()}:\")\n",
    "        print(f\"   Best Val Acc: {best_result['final_val_acc']:.4f}\")\n",
    "        print(f\"   Learning Rate: {best_result['learning_rate']}\")\n",
    "        print(f\"   Batch Size: {best_result['batch_size']}\")\n",
    "        print(f\"   Complexity: {best_result['complexity']}\")\n",
    "        print(f\"   Dropout: {best_result['dropout_rate']}\")\n",
    "        print(f\"   Overfitting: {best_result['overfitting']:.4f}\")\n",
    "        print(f\"   Parameters: {best_result['parameters']:,}\")\n",
    "    \n",
    "    # Display top 5 overall\n",
    "    print(\"\\nüåü TOP 5 OVERALL RESULTS:\")\n",
    "    top_5 = df_results.nlargest(5, 'final_val_acc')[['model_type', 'learning_rate', 'batch_size', \n",
    "                                                      'complexity', 'final_val_acc', 'overfitting']]\n",
    "    print(top_5.to_string(index=False))\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No successful experiments to analyze!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "if len(df_results) > 0:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # 1. Validation Accuracy by Learning Rate\n",
    "    df_results.boxplot(column='final_val_acc', by='learning_rate', ax=axes[0,0])\n",
    "    axes[0,0].set_title('Validation Accuracy by Learning Rate')\n",
    "    \n",
    "    # 2. Validation Accuracy by Batch Size\n",
    "    df_results.boxplot(column='final_val_acc', by='batch_size', ax=axes[0,1])\n",
    "    axes[0,1].set_title('Validation Accuracy by Batch Size')\n",
    "    \n",
    "    # 3. Validation Accuracy by Complexity\n",
    "    df_results.boxplot(column='final_val_acc', by='complexity', ax=axes[0,2])\n",
    "    axes[0,2].set_title('Validation Accuracy by Complexity')\n",
    "    \n",
    "    # 4. Overfitting by Model Type\n",
    "    df_results.boxplot(column='overfitting', by='model_type', ax=axes[1,0])\n",
    "    axes[1,0].set_title('Overfitting by Model Type')\n",
    "    axes[1,0].axhline(y=0, color='r', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # 5. Training Time by Complexity\n",
    "    df_results.boxplot(column='experiment_time', by='complexity', ax=axes[1,1])\n",
    "    axes[1,1].set_title('Training Time by Complexity')\n",
    "    \n",
    "    # 6. Validation Accuracy vs Overfitting\n",
    "    for model_type in df_results['model_type'].unique():\n",
    "        model_data = df_results[df_results['model_type'] == model_type]\n",
    "        axes[1,2].scatter(model_data['overfitting'], model_data['final_val_acc'], \n",
    "                         label=model_type, alpha=0.7)\n",
    "    axes[1,2].set_xlabel('Overfitting (Train Acc - Val Acc)')\n",
    "    axes[1,2].set_ylabel('Validation Accuracy')\n",
    "    axes[1,2].set_title('Validation Accuracy vs Overfitting')\n",
    "    axes[1,2].legend()\n",
    "    axes[1,2].axvline(x=0, color='r', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No data to visualize\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. üîó Quick Fusion Strategy Test\n",
    "\n",
    "Test late fusion dengan parameter terbaik yang ditemukan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df_results) > 0:\n",
    "    print(\"üîó TESTING FUSION STRATEGIES...\")\n",
    "    \n",
    "    # Get best parameters for each model type\n",
    "    cnn_best = df_results[df_results['model_type'] == 'cnn'].loc[df_results[df_results['model_type'] == 'cnn']['final_val_acc'].idxmax()]\n",
    "    landmark_best = df_results[df_results['model_type'] == 'landmark'].loc[df_results[df_results['model_type'] == 'landmark']['final_val_acc'].idxmax()]\n",
    "    \n",
    "    print(f\"Best CNN params: LR={cnn_best['learning_rate']}, BS={cnn_best['batch_size']}, Complexity={cnn_best['complexity']}\")\n",
    "    print(f\"Best Landmark params: LR={landmark_best['learning_rate']}, BS={landmark_best['batch_size']}, Complexity={landmark_best['complexity']}\")\n",
    "    \n",
    "    # Train best models on larger subset\n",
    "    fusion_size = min(3000, X_train_images.shape[0])\n",
    "    X_train_fusion = X_train_images[:fusion_size]\n",
    "    X_train_landmarks_fusion = X_train_landmarks[:fusion_size]\n",
    "    y_train_fusion = y_train_onehot[:fusion_size]\n",
    "    \n",
    "    print(f\"\\nüî¨ Training models on {fusion_size} samples for fusion test...\")\n",
    "    \n",
    "    # Train CNN\n",
    "    cnn_fusion = build_cnn_model(X_train_fusion.shape[1:], num_classes, \n",
    "                                cnn_best['complexity'], cnn_best['dropout_rate'])\n",
    "    cnn_fusion.compile(optimizer=Adam(learning_rate=cnn_best['learning_rate']),\n",
    "                      loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    cnn_fusion.fit(X_train_fusion, y_train_fusion, \n",
    "                  batch_size=int(cnn_best['batch_size']), epochs=10, verbose=0)\n",
    "    \n",
    "    # Train Landmark\n",
    "    landmark_fusion = build_landmark_model(X_train_landmarks_fusion.shape[1], num_classes,\n",
    "                                          landmark_best['complexity'], landmark_best['dropout_rate'])\n",
    "    landmark_fusion.compile(optimizer=Adam(learning_rate=landmark_best['learning_rate']),\n",
    "                           loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    landmark_fusion.fit(X_train_landmarks_fusion, y_train_fusion,\n",
    "                       batch_size=int(landmark_best['batch_size']), epochs=10, verbose=0)\n",
    "    \n",
    "    print(\"‚úÖ Individual models trained!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping fusion test due to insufficient experiment results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different fusion weights\n",
    "if 'cnn_fusion' in locals() and 'landmark_fusion' in locals():\n",
    "    print(\"\\n‚öñÔ∏è Testing different fusion weights...\")\n",
    "    \n",
    "    # Get predictions on validation set\n",
    "    cnn_probs = cnn_fusion.predict(X_val_images[:1000], verbose=0)\n",
    "    landmark_probs = landmark_fusion.predict(X_val_landmarks[:1000], verbose=0)\n",
    "    y_val_true = np.argmax(y_val_onehot[:1000], axis=1)\n",
    "    \n",
    "    # Test different weights\n",
    "    weights = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "    fusion_results = []\n",
    "    \n",
    "    for w_cnn in weights:\n",
    "        w_landmark = 1 - w_cnn\n",
    "        fused_probs = (w_cnn * cnn_probs) + (w_landmark * landmark_probs)\n",
    "        fused_pred = np.argmax(fused_probs, axis=1)\n",
    "        accuracy = accuracy_score(y_val_true, fused_pred)\n",
    "        fusion_results.append((w_cnn, accuracy))\n",
    "        print(f\"CNN Weight: {w_cnn:.1f}, Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # Find best weight\n",
    "    best_weight = max(fusion_results, key=lambda x: x[1])[0]\n",
    "    best_accuracy = max(fusion_results, key=lambda x: x[1])[1]\n",
    "    \n",
    "    print(f\"\\nüèÜ Best fusion weight: CNN={best_weight:.1f}, Landmark={1-best_weight:.1f}\")\n",
    "    print(f\"üèÜ Best fusion accuracy: {best_accuracy:.4f}\")\n",
    "    \n",
    "    # Compare individual vs fusion\n",
    "    cnn_only_acc = accuracy_score(y_val_true, np.argmax(cnn_probs, axis=1))\n",
    "    landmark_only_acc = accuracy_score(y_val_true, np.argmax(landmark_probs, axis=1))\n",
    "    \n",
    "    print(f\"\\nüìä COMPARISON:\")\n",
    "    print(f\"CNN Only: {cnn_only_acc:.4f}\")\n",
    "    print(f\"Landmark Only: {landmark_only_acc:.4f}\")\n",
    "    print(f\"Fusion: {best_accuracy:.4f}\")\n",
    "    \n",
    "    improvement = best_accuracy - max(cnn_only_acc, landmark_only_acc)\n",
    "    print(f\"Improvement: {improvement:.4f} ({improvement*100:.2f}%)\")\n",
    "    \n",
    "    # Plot fusion weights\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    weights_list, accuracies_list = zip(*fusion_results)\n",
    "    plt.plot(weights_list, accuracies_list, 'bo-', label='Fusion')\n",
    "    plt.axhline(y=cnn_only_acc, color='r', linestyle='--', label=f'CNN Only ({cnn_only_acc:.4f})')\n",
    "    plt.axhline(y=landmark_only_acc, color='g', linestyle='--', label=f'Landmark Only ({landmark_only_acc:.4f})')\n",
    "    plt.xlabel('CNN Weight')\n",
    "    plt.ylabel('Validation Accuracy')\n",
    "    plt.title('Late Fusion Performance vs Weight')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Fusion test skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. üíæ Save Results & Recommendations\n",
    "\n",
    "Simpan hasil experiment dan berikan rekomendasi untuk training penuh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare final recommendations\n",
    "recommendations = {\n",
    "    'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'experiment_summary': {\n",
    "        'total_experiments': len(experiment_results),\n",
    "        'successful_experiments': len(successful_results),\n",
    "        'experiment_data_size': experiment_size,\n",
    "        'validation_data_size': val_size\n",
    "    }\n",
    "}\n",
    "\n",
    "if len(df_results) > 0:\n",
    "    # Best parameters for each model\n",
    "    best_configs = {}\n",
    "    \n",
    "    for model_type in df_results['model_type'].unique():\n",
    "        model_results = df_results[df_results['model_type'] == model_type]\n",
    "        best_result = model_results.loc[model_results['final_val_acc'].idxmax()]\n",
    "        \n",
    "        best_configs[model_type] = {\n",
    "            'learning_rate': best_result['learning_rate'],\n",
    "            'batch_size': int(best_result['batch_size']),\n",
    "            'complexity': best_result['complexity'],\n",
    "            'dropout_rate': best_result['dropout_rate'],\n",
    "            'expected_val_acc': best_result['final_val_acc'],\n",
    "            'overfitting_risk': best_result['overfitting']\n",
    "        }\n",
    "    \n",
    "    recommendations['best_configurations'] = best_configs\n",
    "    \n",
    "    # Fusion recommendations\n",
    "    if 'best_weight' in locals():\n",
    "        recommendations['fusion_strategy'] = {\n",
    "            'best_cnn_weight': best_weight,\n",
    "            'best_landmark_weight': 1 - best_weight,\n",
    "            'expected_fusion_acc': best_accuracy,\n",
    "            'improvement_over_individual': improvement\n",
    "        }\n",
    "    \n",
    "    # General recommendations\n",
    "    avg_overfitting = df_results['overfitting'].mean()\n",
    "    recommendations['general_advice'] = {\n",
    "        'average_overfitting': avg_overfitting,\n",
    "        'recommended_epochs': 30 if avg_overfitting < 0.1 else 20,\n",
    "        'use_early_stopping': True,\n",
    "        'early_stopping_patience': 15 if avg_overfitting < 0.1 else 10,\n",
    "        'monitor_metric': 'val_accuracy'\n",
    "    }\n",
    "    \n",
    "    # Save detailed results\n",
    "    with open('experiment_results.pkl', 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'detailed_results': experiment_results,\n",
    "            'recommendations': recommendations\n",
    "        }, f)\n",
    "    \n",
    "    print(\"üíæ Results saved to 'experiment_results.pkl'\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No successful experiments to save\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display final recommendations\n",
    "print(\"=\"*60)\n",
    "print(\"üéØ FINAL RECOMMENDATIONS FOR FULL TRAINING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if 'recommendations' in locals() and 'best_configurations' in recommendations:\n",
    "    print(\"\\nüèÜ BEST CONFIGURATIONS:\")\n",
    "    \n",
    "    for model_type, config in recommendations['best_configurations'].items():\n",
    "        print(f\"\\n{model_type.upper()} MODEL:\")\n",
    "        print(f\"   Learning Rate: {config['learning_rate']}\")\n",
    "        print(f\"   Batch Size: {config['batch_size']}\")\n",
    "        print(f\"   Complexity: {config['complexity']}\")\n",
    "        print(f\"   Dropout Rate: {config['dropout_rate']}\")\n",
    "        print(f\"   Expected Val Acc: {config['expected_val_acc']:.4f}\")\n",
    "        print(f\"   Overfitting Risk: {'High' if config['overfitting_risk'] > 0.15 else 'Medium' if config['overfitting_risk'] > 0.05 else 'Low'}\")\n",
    "    \n",
    "    if 'fusion_strategy' in recommendations:\n",
    "        fusion = recommendations['fusion_strategy']\n",
    "        print(f\"\\nüîó FUSION STRATEGY:\")\n",
    "        print(f\"   Best CNN Weight: {fusion['best_cnn_weight']:.1f}\")\n",
    "        print(f\"   Best Landmark Weight: {fusion['best_landmark_weight']:.1f}\")\n",
    "        print(f\"   Expected Fusion Acc: {fusion['expected_fusion_acc']:.4f}\")\n",
    "        print(f\"   Improvement: {fusion['improvement_over_individual']:.4f} ({fusion['improvement_over_individual']*100:.2f}%)\")\n",
    "    \n",
    "    general = recommendations['general_advice']\n",
    "    print(f\"\\n‚öôÔ∏è TRAINING SETTINGS:\")\n",
    "    print(f\"   Recommended Epochs: {general['recommended_epochs']}\")\n",
    "    print(f\"   Use Early Stopping: {general['use_early_stopping']}\")\n",
    "    print(f\"   Early Stopping Patience: {general['early_stopping_patience']}\")\n",
    "    print(f\"   Monitor Metric: {general['monitor_metric']}\")\n",
    "    \n",
    "    print(\"\\nüìã NEXT STEPS:\")\n",
    "    print(\"   1. Update your training scripts dengan parameter di atas\")\n",
    "    print(\"   2. Jalankan training dengan early stopping\")\n",
    "    print(\"   3. Monitor training progress closely\")\n",
    "    print(\"   4. Jika overfitting, reduce learning rate atau increase dropout\")\n",
    "    print(\"   5. Test fusion strategy setelah individual models selesai\")\n",
    "    \n",
    "    print(\"\\nüöÄ READY FOR FULL TRAINING!\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚ùå No recommendations available due to failed experiments\")\n",
    "    print(\"\\nTroubleshooting tips:\")\n",
    "    print(\"   - Check data paths and loading\")\n",
    "    print(\"   - Verify data shapes and types\")\n",
    "    print(\"   - Try simpler model architectures\")\n",
    "    print(\"   - Check GPU memory availability\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  }\n",
 ],\n",
 "metadata": {\n",
  \"kernelspec\": {\n",
   \"display_name\": \"Python 3\",\n",
   \"language\": \"python\",\n",
   \"name\": \"python3\"\n  },\n  \"language_info\": {\n   \"codemirror_mode\": {\n    \"name\": \"ipython\",\n    \"version\": 3\n   },\n   \"file_extension\": \".py\",\n   \"mimetype\": \"text/x-python\",\n   \"name\": \"python\",\n   \"nbconvert_exporter\": \"python\",\n   \"pygments_lexer\": \"ipython3\",\n   \"version\": \"3.8.0\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 4\n}